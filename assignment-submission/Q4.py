# Manish Kumar 21044

import numpy as np
from sklearn import linear_model

# Variable X 
x= [[-0.367, 0.645, 0.389, -0.587, -0.481],
 [-0.488, 0.881, -0.134, -0.852, -0.416],
 [0.038, 0.303, 0.459, 0.243, 0.761],
 [0.557, -0.431, -0.931, -0.145, 0.384],
 [-0.362, 0.611, -0.384, -0.768, -0.371],
 [0.832, -0.099, -0.017, 0.159, 0.375],
 [-0.176, 0.315, 0.178, -0.162, -0.157],
 [0.458, 0.417, 0.514, -0.476, -0.502],
 [-0.162, 0.191, 0.807, 0.016, 0.887],
 [-0.396, 0.334, 0.72, -0.561, 0.791],
 [-0.051, -0.991, 0.454, -0.93, -0.211],
 [-0.087, -0.318, -0.431, -0.634, 0.512],
 [0.078, 0.408, -0.963, -0.745, 0.672],
 [0.562, 0.462, 0.439, 0.762, 0.933],
 [-0.355, 0.586, -0.609, 0.493, 0.348],
 [-0.732, 0.009, -0.648, 0.621, 0.023],
 [-0.707, 0.413, -0.419, 0.823, -0.923],
 [-0.096, -0.597, -0.181, -0.804, -0.525],
 [-0.809, -0.258, -0.225, -0.583, -0.316],
 [-0.067, 0.688, -0.013, -0.942, -0.199],
 [0.308, -0.947, -0.513, 0.662, 0.225],
 [0.397, -0.243, -0.955, -0.21, 0.935],
 [0.592, 0.607, -0.103, -0.706, -0.706],
 [-0.664, 0.067, 0.469, -0.016, -0.377],
 [-0.082, 0.838, 0.558, 0.53, -0.991],
 [-0.38, 0.583, -0.364, -0.811, 0.044],
 [0.412, -0.484, 0.547, 0.196, 0.297],
 [-0.907, 0.3, 0.939, 0.329, -0.895],
 [0.336, 0.026, 0.512, 0.112, -0.983],
 [0.663, 0.458, 0.757, 0.197, -0.045],
 [0.802, 0.142, 0.142, 0.249, 0.532],
 [-0.308, -0.043, 0.519, -0.902, 0.377],
 [-0.122, 0.992, -0.038, -0.367, -0.742],
 [0.809, 0.242, 0.163, -0.951, 0.241],
 [-0.881, 0.407, 0.829, -0.861, 0.407],
 [0.737, 0.075, 0.336, -0.228, -0.35],
 [0.322, 0.119, -0.076, 0.842, -0.908],
 [-0.198, -0.462, 0.354, -0.316, -0.917],
 [0.199, -0.559, -0.891, -0.794, -0.955],
 [0.847, -0.899, 0.609, -0.85, -0.817],
 [0.329, 0.084, -0.386, -0.156, 0.26]
 , [-0.557, -0.38, 0.664, -0.013, 0.595]
 , [-0.952, -0.143, -0.184, -0.898, -0.107]
 , [-0.752, 0.423, -0.18, 0.706, 0.33]
 , [0.747, -0.435, 0.544, 0.489, 0.011]
 , [-0.964, -0.043, -0.326, 0.833, 0.023]
 , [0.6, -0.519, -0.746, -0.31, -0.517]
 , [0.322, 0.606, -0.17, -0.546, 0.045]
, [0.821, 0.31, -0.803, -0.891, 0.305]
 , [-0.873, -0.781, -0.747, -0.988, -0.735]
 , [0.693, 0.139, 0.591, 0.571, -0.136]
 , [0.702, 0.25, -0.729, 0.0, 0.551]
 , [-0.276, -0.78, 0.164, 0.666, -0.011]
 , [-0.954, 0.618, 0.322, 0.4, 0.413]
 , [0.355, -0.47, -0.296, -0.017, -0.144]
 , [-0.985, -0.963, 0.428, -0.519, -0.548]
 , [0.848, 0.625, -0.981, -0.723, -0.791]
 , [0.046, -0.803, -0.862, 0.683, -0.22]
 , [0.976, -0.665, 0.47, 0.138, -0.946]
 , [-0.114, 0.201, -0.464, 0.791, -0.856]
 , [0.9, 0.999, -0.697, 0.86, 0.141]
 , [0.033, -0.418, -0.455, -0.254, -0.27]
 , [-0.83, -0.516, 0.042, 0.996, 0.787]
 , [-0.43, -0.767, 0.471, 0.242, -0.741]
 , [-0.266, -0.11, -0.407, 0.195, 0.955]
 , [-0.997, -0.195, 0.279, 0.62, -0.868]
 , [0.675, -0.928, -0.391, 0.435, 0.425]
 , [0.814, 0.624, -0.292, 0.393, -0.39]
 , [0.982, -0.313, 0.439, 0.448, -0.442]
 , [-0.826, 0.241, -0.868, 0.481, -0.48]
 , [-0.191, -0.722, 0.672, -0.369, 0.603]
 , [-0.285, 0.318, -0.857, 0.791, 0.536]
 , [0.509, -0.017, -0.526, -0.258, 0.823]
 , [-0.185, -0.687, -0.451, 0.953, 0.047]
 , [-0.425, -0.417, -0.126, -0.418, -0.067]
 , [0.152, -0.687, 0.084, -0.932, -0.098]
 , [0.313, -0.026, -0.553, -0.599, 0.74]
 , [0.596, 0.878, -0.077, -0.279, -0.407]
 , [-0.772, -0.397, 0.27, 0.445, -0.19]
 , [0.69, -0.487, 0.017, -0.11, -0.844]
 , [-0.283, -0.724, 0.256, 0.454, 0.284]
 , [0.448, 0.744, 0.923, -0.171, 0.129]
 , [-0.869, -0.027, 0.527, -0.566, 0.078]
 , [0.47, -0.231, -0.881, -0.983, 0.854]
 , [0.43, 0.071, -0.554, 0.989, -0.18]
 , [0.37, 0.123, 0.409, -0.717, -0.552]
, [0.426, 0.224, -0.542, -0.908, 0.294]
 , [-0.841, -0.621, 0.557, -0.784, 0.41]
 , [-0.532, -0.613, 0.941, 0.035, 0.283]
, [0.323, -0.49, -0.295, 0.856, 0.789]
 , [-0.234, -0.438, 0.84, -0.778, -0.371]
, [-0.366, -0.275, 0.789, -0.534, 0.899]
 , [-0.482, 0.905, -0.618, 0.784, 0.179]
, [0.696, -0.628, 0.627, -0.046, 0.011]
 , [-0.162, -0.983, -0.914, -0.142, 0.014]
, [-0.52, -0.126, 0.01, -0.388, -0.853]
 , [-0.815, -0.325, -0.215, 0.915, -0.314]
 , [0.059, 0.983, 0.557, -0.945, -0.949]
 , [0.28, 0.999, -0.577, -0.837, -0.525]
 , [-0.453, -0.637, 0.848, 0.902, 0.696]]

y= [-0.865, 
 -0.730, 
 -1.592, 
 -0.553, 
 -0.567, 
 -1.161, 
 -0.891, 
 -0.988, 
 -1.700, 
 -1.570, 
 -0.380, 
 -0.708, 
 -0.902, 
 -1.900, 
 -0.973, 
 -0.467, 
 -0.239, 
 -0.107, 
 -0.222, 
 -0.897, 
 -0.446, 
 -0.887, 
 -0.701, 
 -0.702, 
 -0.899, 
 -0.785,
 -1.112, 
 -0.698,
 -0.586, 
 -1.464, 
 -1.420, 
 -1.084, 
 -0.758, 
 -1.203, 
 -1.310, 
 -0.931, 
 -0.480, 
 -0.199, 
 0.354,
 -0.342,
 -0.887,
 -1.153, 
 -0.345,
 -1.015,
 -1.069, 
 -0.554, 
 -0.092, 
 -1.045, 
 -0.864, 
 0.503, 
 -1.248,
 -1.062, 
 -0.556, 
 -1.288,
 -0.485, 
 -0.042,
 -0.340, 
 -0.062, 
 -0.428, 
 -0.285, 
 -1.287, 
 -0.284, 
 -0.972, 
 -0.220, 
 -1.089, 
 -0.230, 
 -0.671, 
 -0.948, 
 -0.871,
 -0.164, 
 -1.057, 
 -0.900,
 -1.122, 
 -0.411, 
 -0.427, 
 -0.456, 
 -0.990, 
 -1.031, 
 -0.544,
 -0.286, 
 -0.760, 
 -1.675, 
 -0.845, 
 -0.824, 
 -0.693, 
 -0.752, 
 -0.850, 
 -0.774,
 -1.009,
 -1.065,
 -0.667,
 -1.409,
 -1.013,
 -0.963,
 0.024,
 -0.159,
 -0.334,
 -0.877,
 -0.691 ,
 -1.282]

regr = linear_model.LinearRegression()

regr.fit(x, y)

print('w: \n', regr.coef_)
print('b: \n', regr.intercept_)

# rounding upto two decimal point
w=[]
for value in regr.coef_:
    w.append(round(value, 2))
    
# final answer
print('w upto two decimal points: \n',w)